# DnD RAG Chatbot

An AI-powered assistant that learns Dungeons & Dragons (D&D 5e) rules from PDFs, answers rules questions using a RAG (Retrieval-Augmented Generation) pipeline, and falls back to web search + a cloud LLM when local context is not enough.

> **Status:** Early development â€“ core environment, local LLM connectivity, Claude API connectivity, and PDF processing scripts are set up.

---

## âœ¨ Features (Planned)

- ğŸ“š **Rule-aware DnD assistant**  
  Answers rules questions using official D&D PDFs (Playerâ€™s Handbook, DMG, etc.) via a vector-search-backed RAG pipeline.

- ğŸ§  **Hybrid RAG system**
  - Local Llama 3.1 8B (via Ollama) as the primary model
  - Sentence-transformer embeddings stored in ChromaDB / FAISS
  - Optional re-ranking for higher-quality retrieval

- ğŸŒ **Web-enhanced fallback**
  - If confidence in the RAG answer is low, the system:
    1. Searches the web and scrapes relevant pages  
    2. Calls Claude (Haiku 4) with both the original question and fetched content  
    3. Returns an answer clearly marked as â€œweb-enhancedâ€

- ğŸ§± **Modular architecture**
  - Clean separation between config, LLM tests, PDF processing, and future RAG pipeline
  - Designed to grow into a full FastAPI backend + simple web UI (Streamlit/Gradio)

- ğŸ§ª **Evaluation & safety focus (planned)**
  - Test question set (50â€“100 questions)
  - Accuracy, response time, hallucination rate, and user feedback tracking

A detailed 8â€“10 week roadmap for this project (from setup to deployment) is documented in the project planning document. :contentReference[oaicite:0]{index=0}

---

## ğŸ— Architecture Overview

High-level flow:

1. **User question** (e.g., â€œHow does a saving throw work in 5e?â€)
2. **Query preprocessing**
   - Spell check
   - Named entity extraction (spells, classes, conditions)
   - Optional query expansion
3. **Vector similarity search**
   - ChromaDB / FAISS
   - Top-k (3â€“5) most relevant chunks from D&D PDFs
   - Metadata filtering by book / chapter / page
4. **(Optional) Re-ranking**
   - Cross-encoder re-ranks retrieved chunks for better relevance
5. **Local LLM answer (Llama 3.1 8B via Ollama)**
   - Prompt template combines context + user question
   - Confidence score computed from answer heuristics
6. **Fallback decision**
   - If `confidence >= threshold` â†’ return answer + PDF sources
   - Else:
     - Run web search + scraping
     - Ask Claude (Haiku 4) with combined context
     - Return â€œweb-enhancedâ€ answer + sources

---

## ğŸ§° Tech Stack

**LLMs & AI**
- Local: Llama 3.1 8B (via Ollama)
- Cloud: Claude Haiku 4 (Anthropic API)
- Embeddings: `sentence-transformers`
- RAG Framework: LangChain / LlamaIndex (planned)

**Storage**
- Vector DB: ChromaDB / FAISS
- File data: D&D rule PDFs under `data/pdfs/`
- Vector index under `data/chroma_db/`

**Backend & Tools**
- Python 3.10+
- FastAPI (planned)
- Streamlit / Gradio for prototype UI (planned)

**Utilities**
- PDF processing: PyMuPDF (`pymupdf`), `pypdf2`, `pdfplumber`
- Web scraping: `requests`, `beautifulsoup4`, Selenium
- Environment & config: `python-dotenv`, `Config` class in `src/config.py`

The first week of work focuses on VS Code setup, environment creation, LLM/API tests, and PDF processing, as outlined in the detailed Week 1 plan. :contentReference[oaicite:1]{index=1}

---

## ğŸ“ Project Structure

```txt
dnd-chatbot/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py          # Project configuration & paths
â”‚   â”œâ”€â”€ test_ollama.py     # Local Llama / Ollama connectivity test
â”‚   â”œâ”€â”€ test_claude.py     # Claude API connectivity test
â”‚   â”œâ”€â”€ pdf_processor.py   # PDF listing, metadata & text extraction
â”‚   â””â”€â”€ integration_test.py# End-to-end environment sanity check
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ pdfs/              # Place DnD rule PDFs here
â”‚   â””â”€â”€ chroma_db/         # Vector database files (Chroma / FAISS)
â”œâ”€â”€ tests/                 # (Reserved for future unit/integration tests)
â”œâ”€â”€ .env                   # API keys & environment variables (not committed)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
