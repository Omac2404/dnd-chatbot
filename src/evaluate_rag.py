"""
RAG sistemini deÄŸerlendir
Accuracy, response time, retrieval quality Ã¶lÃ§Ã¼m
"""

import time
from typing import List, Dict
from rag_pipeline import RAGPipeline
from test_questions import TEST_QUESTIONS


class RAGEvaluator:
    """RAG evaluation sÄ±nÄ±fÄ±"""
    
    def __init__(self, rag_pipeline: RAGPipeline):
        self.rag = rag_pipeline
        self.results = []
    
    def evaluate_answer_quality(self, answer: str, expected_keywords: List[str]) -> float:
        """
        CevabÄ±n kalitesini expected keywords'e gÃ¶re deÄŸerlendir
        
        Returns:
            0.0 - 1.0 arasÄ± skor
        """
        answer_lower = answer.lower()
        found_keywords = sum(1 for keyword in expected_keywords if keyword.lower() in answer_lower)
        
        return found_keywords / len(expected_keywords) if expected_keywords else 0.0
    
    def evaluate_retrieval_quality(self, question: str, retrieved_docs: List[Dict], expected_keywords: List[str]) -> float:
        """Retrieved document'larÄ±n kalitesini deÄŸerlendir"""
        
        # Retrieved text'leri birleÅŸtir
        if retrieved_docs and 'text_preview' in retrieved_docs[0]:
            all_retrieved_text = " ".join([doc['text_preview'] for doc in retrieved_docs]).lower()
        else:
            all_retrieved_text = " ".join([doc.get('text', '') for doc in retrieved_docs]).lower()
        
        # Expected keywords kaÃ§Ä± var?
        found_keywords = sum(1 for keyword in expected_keywords if keyword.lower() in all_retrieved_text)
        
        # Ã–NEMLÄ°: RETURN SATIRI OLMALI!
        return found_keywords / len(expected_keywords) if expected_keywords else 0.0
    
    def run_evaluation(self, test_questions: List[Dict] = None):
        """TÃ¼m test sorularÄ±nÄ± Ã§alÄ±ÅŸtÄ±r ve deÄŸerlendir"""
        
        if test_questions is None:
            test_questions = TEST_QUESTIONS
        
        print("="*60)
        print("RAG EVALUATION")
        print("="*60)
        print(f"Toplam {len(test_questions)} test sorusu\n")
        
        for i, test_case in enumerate(test_questions, 1):
            print(f"\n{'='*60}")
            print(f"TEST {i}/{len(test_questions)}: {test_case['category']}")
            print(f"{'='*60}")
            print(f"Soru: {test_case['question']}")
            
            # Timing
            start_time = time.time()
            
            # RAG query
            result = self.rag.query(test_case['question'], top_k=5)
            
            # Retrieval iÃ§in ayrÄ± timing
            retrieval_docs = self.rag.retrieve_context(test_case['question'], top_k=5)
            
            elapsed_time = time.time() - start_time
            
            # Evaluate
            answer_quality = self.evaluate_answer_quality(
                result['answer'], 
                test_case['expected_keywords']
            )
            
            retrieval_quality = self.evaluate_retrieval_quality(
                test_case['question'],
                result['sources'],
                test_case['expected_keywords']
            )
            
            confidence = self.rag.calculate_confidence(result['answer'])
            
            # Store result
            eval_result = {
                "question": test_case['question'],
                "category": test_case['category'],
                "answer": result['answer'],
                "answer_quality": answer_quality,
                "retrieval_quality": retrieval_quality,
                "confidence": confidence,
                "response_time": elapsed_time,
                "sources_used": len(result['sources'])
            }
            
            self.results.append(eval_result)
            
            # Print result
            print(f"\nğŸ“Š Skorlar:")
            print(f"   Answer Quality: {answer_quality:.2%}")
            print(f"   Retrieval Quality: {retrieval_quality:.2%}")
            print(f"   Confidence: {confidence:.2%}")
            print(f"   Response Time: {elapsed_time:.2f}s")
            
            # CevabÄ±n kÄ±sa Ã¶nizlemesi
            print(f"\nğŸ’¬ Cevap Preview:")
            print(f"   {result['answer'][:200]}...")
        
        # Overall stats
        self.print_overall_stats()
    
    def print_overall_stats(self):
        """Genel istatistikleri yazdÄ±r"""
        
        if not self.results:
            print("\nâŒ HenÃ¼z sonuÃ§ yok!")
            return
        
        print("\n" + "="*60)
        print("GENEL Ä°STATÄ°STÄ°KLER")
        print("="*60)
        
        # Calculate averages
        avg_answer_quality = sum(r['answer_quality'] for r in self.results) / len(self.results)
        avg_retrieval_quality = sum(r['retrieval_quality'] for r in self.results) / len(self.results)
        avg_confidence = sum(r['confidence'] for r in self.results) / len(self.results)
        avg_response_time = sum(r['response_time'] for r in self.results) / len(self.results)
        
        print(f"\nğŸ“ˆ Ortalama Skorlar:")
        print(f"   Answer Quality: {avg_answer_quality:.2%}")
        print(f"   Retrieval Quality: {avg_retrieval_quality:.2%}")
        print(f"   Confidence: {avg_confidence:.2%}")
        print(f"   Response Time: {avg_response_time:.2f}s")
        
        # Category breakdown
        print(f"\nğŸ“Š Kategori BazlÄ±:")
        categories = {}
        for result in self.results:
            cat = result['category']
            if cat not in categories:
                categories[cat] = []
            categories[cat].append(result['answer_quality'])
        
        for cat, scores in categories.items():
            avg_score = sum(scores) / len(scores)
            print(f"   {cat}: {avg_score:.2%} ({len(scores)} soru)")
        
        # Pass/Fail
        passed = sum(1 for r in self.results if r['answer_quality'] >= 0.6)
        total = len(self.results)
        
        print(f"\nâœ… BaÅŸarÄ± OranÄ±: {passed}/{total} ({passed/total:.1%})")
        
        if avg_answer_quality >= 0.75:
            print("\nğŸ‰ RAG sistemi iyi performans gÃ¶steriyor!")
        elif avg_answer_quality >= 0.6:
            print("\nâš ï¸ RAG sistemi orta performans gÃ¶steriyor. Ä°yileÅŸtirme yapÄ±labilir.")
        else:
            print("\nâŒ RAG sistemi zayÄ±f performans gÃ¶steriyor. Optimizasyon gerekli!")


def main():
    """Evaluation test scripti"""
    
    print("="*60)
    print("RAG SYSTEM EVALUATION")
    print("="*60 + "\n")
    
    # RAG pipeline oluÅŸtur
    rag = RAGPipeline(use_local_llm=True)
    
    # Evaluator oluÅŸtur
    evaluator = RAGEvaluator(rag)
    
    # Evaluation Ã§alÄ±ÅŸtÄ±r
    evaluator.run_evaluation()
    
    print("\nâœ… Evaluation tamamlandÄ±!")


if __name__ == "__main__":
    main()